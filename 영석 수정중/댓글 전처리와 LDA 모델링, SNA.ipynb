{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBRFqY0ScHvt"
   },
   "source": [
    "# 한글 댓글 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time, requests, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ofhYXGNMcHvx",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>청담 파인다이닝 도쿄등심에서 이렇게 한우를 드세요도쿄등심 청담점에 다녀왔습니다.누네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>날씨도 추워졌겠다 오랜만에 너덜너덜해진 열손가락의 꽃단장을 위하여 덕천동 네일로 향...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>안녕하세요, 도쿄드라이브입니다. 최근 롤렉스나 에르메스의 인기모델들은 정식매장에 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021.11.17 아침 사진이 하나뚜 없ㄴㅔ건강보험 뭐 우편 온거 땜에 일어나서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>곧 다가올 와이프님과의 5주년 결혼기념일.​포근한 주말을 맞이하여 분당에서 광교앨리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>와 나 300일이나 여기에 살았네..3일째랑 30일째 되는 날엔 뭘 했지...?기억...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>선릉역 소고기 맛집 도쿄등심선릉점 와이프와 함께 코엑스 전시보고 맛있는 소고기 먹으...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>작은도쿄평일 11:30~21:00브레이크타임 15:00~17:00토일,공휴일 휴무숙...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>도곡동 맛집 분위기 끝판왕 도쿄등심 도곡점​​​ ​​*  안녕하세요 제이드입니다. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>여의도는 수많은 빌딩들이 밀집되어 있어화려한 건축물의 조명등으로 야경이 아름다운  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>도쿄등심 여의도점 - 분위기 좋은 여의도 데이트 맛집, 기념일 맛집으로 추천해!​안...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>​오늘은 히나랑 디~즈니란도 가는 날 ~JR 시계 여기는 스페이드모양이다 귀여워마이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>도쿄에서는 단풍이 절정을 맞이하고 있어요!오늘은 추천 단풍명소를 소개해 드릴게요. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021년 11월의 기록...PART 1이제 슬슬 노랑 노랑해지기 시작한.....도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>안녕하세요, 도쿄드라이브입니다. 긴자(銀座)는 쇼핑하기 참좋은 도쿄의 유명 관광스팟...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>도쿄 리벤저스 만화 원화전 , 오사카서 내년 열려 티저 비주얼 공개와쿠이 켄 도쿄...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021.11.16 (화) 329일차​​​​6:30-11 도토루하 데마에칸 진짜,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>​ 일본유학 중국유학북경어언대학교 도쿄분교​ ​​중국의 북경어언대학교는1962년 중...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>오늘은 충동질로 버스표 끊은 카와구치코 가는 날^^일기예보도 안보고 아 갈까? 가야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>디너코스 B 으로 먹었어요남편과 저 둘이서 간만에 데이트 하는느낌으로 먹었는데 분위...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>광교에 간 김에 점심을 먹으러 앨리웨이(Alleyway)에 갔다. &lt; 광교 앨리웨이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>smartparty.jp곤니치와 ~^^\"일본여행 크리에이터 난짱이야.​​먼저 매번 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>오늘은 👶 기다리는 요미우리랜드 ( 🎡 유원지 ) 遊園地よみうりランド遊園地よみうりラ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>아 얘들아 내가 아직 얘길 안했지 아이폰13 샀다고...(출시때 직구함)(미니 스타...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>남친보다 친구만나는날에 더 머리랑 화장을 공들여한다...왜냐..사진 오조억장 찍거든...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>안녕하세요, 도쿄드라이브입니다. 이번 포스팅은 도쿄의 트렌디한 고급동네 오모테산도(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>아트를 좋아하시는 분이 놓치면 후회할 호텔을 소개해 드릴게요! ​   도쿄·신바시에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>안녕하세요, 도쿄드라이브입니다. 일본 도쿄에서 쇼핑하기 좋은 동네는 몇군데 있는데요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>오늘은 탈리즈 7-10시프트!끝나고 뭐할까 고민하다가이제 있을 시간도 얼마 안남았으...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>안녕하세요, 도쿄드라이브입니다. 최근 도쿄는 긴급사태선언(緊急事態宣言)이 끝나고, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body\n",
       "0   청담 파인다이닝 도쿄등심에서 이렇게 한우를 드세요도쿄등심 청담점에 다녀왔습니다.누네...\n",
       "1   날씨도 추워졌겠다 오랜만에 너덜너덜해진 열손가락의 꽃단장을 위하여 덕천동 네일로 향...\n",
       "2   안녕하세요, 도쿄드라이브입니다. 최근 롤렉스나 에르메스의 인기모델들은 정식매장에 가...\n",
       "3   2021.11.17 아침 사진이 하나뚜 없ㄴㅔ건강보험 뭐 우편 온거 땜에 일어나서 ...\n",
       "4   곧 다가올 와이프님과의 5주년 결혼기념일.​포근한 주말을 맞이하여 분당에서 광교앨리...\n",
       "5   와 나 300일이나 여기에 살았네..3일째랑 30일째 되는 날엔 뭘 했지...?기억...\n",
       "6   선릉역 소고기 맛집 도쿄등심선릉점 와이프와 함께 코엑스 전시보고 맛있는 소고기 먹으...\n",
       "7   작은도쿄평일 11:30~21:00브레이크타임 15:00~17:00토일,공휴일 휴무숙...\n",
       "8   도곡동 맛집 분위기 끝판왕 도쿄등심 도곡점​​​ ​​*  안녕하세요 제이드입니다. ...\n",
       "9   여의도는 수많은 빌딩들이 밀집되어 있어화려한 건축물의 조명등으로 야경이 아름다운  ...\n",
       "10  도쿄등심 여의도점 - 분위기 좋은 여의도 데이트 맛집, 기념일 맛집으로 추천해!​안...\n",
       "11  ​오늘은 히나랑 디~즈니란도 가는 날 ~JR 시계 여기는 스페이드모양이다 귀여워마이...\n",
       "12  도쿄에서는 단풍이 절정을 맞이하고 있어요!오늘은 추천 단풍명소를 소개해 드릴게요. ...\n",
       "13  2021년 11월의 기록...PART 1이제 슬슬 노랑 노랑해지기 시작한.....도...\n",
       "14  안녕하세요, 도쿄드라이브입니다. 긴자(銀座)는 쇼핑하기 참좋은 도쿄의 유명 관광스팟...\n",
       "15   도쿄 리벤저스 만화 원화전 , 오사카서 내년 열려 티저 비주얼 공개와쿠이 켄 도쿄...\n",
       "16  2021.11.16 (화) 329일차​​​​6:30-11 도토루하 데마에칸 진짜,,...\n",
       "17  ​ 일본유학 중국유학북경어언대학교 도쿄분교​ ​​중국의 북경어언대학교는1962년 중...\n",
       "18  오늘은 충동질로 버스표 끊은 카와구치코 가는 날^^일기예보도 안보고 아 갈까? 가야...\n",
       "19  디너코스 B 으로 먹었어요남편과 저 둘이서 간만에 데이트 하는느낌으로 먹었는데 분위...\n",
       "20  광교에 간 김에 점심을 먹으러 앨리웨이(Alleyway)에 갔다. < 광교 앨리웨이...\n",
       "21  smartparty.jp곤니치와 ~^^\"일본여행 크리에이터 난짱이야.​​먼저 매번 ...\n",
       "22  오늘은 👶 기다리는 요미우리랜드 ( 🎡 유원지 ) 遊園地よみうりランド遊園地よみうりラ...\n",
       "23  아 얘들아 내가 아직 얘길 안했지 아이폰13 샀다고...(출시때 직구함)(미니 스타...\n",
       "24  남친보다 친구만나는날에 더 머리랑 화장을 공들여한다...왜냐..사진 오조억장 찍거든...\n",
       "25  안녕하세요, 도쿄드라이브입니다. 이번 포스팅은 도쿄의 트렌디한 고급동네 오모테산도(...\n",
       "26  아트를 좋아하시는 분이 놓치면 후회할 호텔을 소개해 드릴게요! ​   도쿄·신바시에...\n",
       "27  안녕하세요, 도쿄드라이브입니다. 일본 도쿄에서 쇼핑하기 좋은 동네는 몇군데 있는데요...\n",
       "28  오늘은 탈리즈 7-10시프트!끝나고 뭐할까 고민하다가이제 있을 시간도 얼마 안남았으...\n",
       "29  안녕하세요, 도쿄드라이브입니다. 최근 도쿄는 긴급사태선언(緊急事態宣言)이 끝나고, ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/twentystones/Desktop/사회연결망분석텀프로젝트/blog_crawling.csv', encoding='utf-8-sig', header=None)\n",
    "df.rename(columns= {0:'title', 1:'URL', 2:'day', 3:'body'}, inplace=True)\n",
    "df = df.iloc[:,3:]\n",
    "df = df.fillna('')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TyVD0ZWYcHvz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:04<00:00,  6.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# 명사 추출\n",
    "comment_okt_nouns = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    comment_okt_nouns.append(okt.nouns(df.body[i]))\n",
    "df['comment_okt_nouns'] = comment_okt_nouns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#한글자짜리 지우기\n",
    "comment_okt_nouns_len = []\n",
    "for i in range(len(df)):\n",
    "    comment_okt_nouns_len.append([])\n",
    "\n",
    "for i in range(len(comment_okt_nouns)):\n",
    "    for word in comment_okt_nouns[i]:\n",
    "        if len(word)!=1:\n",
    "            comment_okt_nouns_len[i].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지칭 불용어 제거\n",
    "stop_words_noun = ['사람','다음','정도', '하나', '이거', '여기', '이번', '인간', '어디','겁니다','이게','저거','이건','걸로','그거','그걸','그게','저기','그것','이것','저것','무엇','어디']\n",
    "comment_okt_nouns_len_stp = []\n",
    "for i in range(len(df)):\n",
    "    comment_okt_nouns_len_stp.append([])\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for word in comment_okt_nouns_len[i]:\n",
    "        if word not in stop_words_noun:\n",
    "            comment_okt_nouns_len_stp[i].append(word)\n",
    "df['comment_okt_nouns_len_stp'] = comment_okt_nouns_len_stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>comment_okt_nouns</th>\n",
       "      <th>comment_okt_nouns_len_stp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>청담 파인다이닝 도쿄등심에서 이렇게 한우를 드세요도쿄등심 청담점에 다녀왔습니다.누네...</td>\n",
       "      <td>[청담, 다이닝, 도쿄, 등심, 한우, 도쿄, 등심, 청담, 점, 누, 안과, 신랑...</td>\n",
       "      <td>[청담, 다이닝, 도쿄, 등심, 한우, 도쿄, 등심, 청담, 안과, 신랑, 라섹, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>날씨도 추워졌겠다 오랜만에 너덜너덜해진 열손가락의 꽃단장을 위하여 덕천동 네일로 향...</td>\n",
       "      <td>[날씨, 만, 손가락, 꽃, 단장, 위, 덕천동, 네일, 향, 제, 성격, 좀, 무...</td>\n",
       "      <td>[날씨, 손가락, 단장, 덕천동, 네일, 성격, 무딘편, 변화, 대해, 크게, 신경...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>안녕하세요, 도쿄드라이브입니다. 최근 롤렉스나 에르메스의 인기모델들은 정식매장에 가...</td>\n",
       "      <td>[도쿄, 드라이브, 최근, 롤렉스, 에르메스, 인기, 모델, 정식, 매장, 가면, ...</td>\n",
       "      <td>[도쿄, 드라이브, 최근, 롤렉스, 에르메스, 인기, 모델, 정식, 매장, 가면, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021.11.17 아침 사진이 하나뚜 없ㄴㅔ건강보험 뭐 우편 온거 땜에 일어나서 ...</td>\n",
       "      <td>[아침, 사진, 하나, 뚜, 건강, 보험, 뭐, 우편, 땜, 일어나서, 고구마, 고...</td>\n",
       "      <td>[아침, 사진, 건강, 보험, 우편, 일어나서, 고구마, 고민, 기어, 사실, 약간...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>곧 다가올 와이프님과의 5주년 결혼기념일.​포근한 주말을 맞이하여 분당에서 광교앨리...</td>\n",
       "      <td>[곧, 와이프, 주년, 결혼기념일, 주말, 맞이, 분당, 광교, 앨리, 웨이, 데이...</td>\n",
       "      <td>[와이프, 주년, 결혼기념일, 주말, 맞이, 분당, 광교, 앨리, 웨이, 데이트, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>와 나 300일이나 여기에 살았네..3일째랑 30일째 되는 날엔 뭘 했지...?기억...</td>\n",
       "      <td>[나, 여기, 날, 뭘, 기억, 힝, 이제, 집, 전철, 때, 쭉, 신주쿠, 히가시...</td>\n",
       "      <td>[기억, 이제, 전철, 신주쿠, 히가시구, 치쪽, 해도, 진단, 오늘, 오픈, 멤버...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>선릉역 소고기 맛집 도쿄등심선릉점 와이프와 함께 코엑스 전시보고 맛있는 소고기 먹으...</td>\n",
       "      <td>[선릉역, 소고기, 맛집, 도쿄, 등심, 선릉, 점, 와이프, 코엑스, 전시, 보고...</td>\n",
       "      <td>[선릉역, 소고기, 맛집, 도쿄, 등심, 선릉, 와이프, 코엑스, 전시, 보고, 소...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>작은도쿄평일 11:30~21:00브레이크타임 15:00~17:00토일,공휴일 휴무숙...</td>\n",
       "      <td>[도쿄, 평일, 브레이크, 타임, 토일, 공휴일, 휴무, 숙대입구역, 근처, 늘, ...</td>\n",
       "      <td>[도쿄, 평일, 브레이크, 타임, 토일, 공휴일, 휴무, 숙대입구역, 근처, 웨이팅...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>도곡동 맛집 분위기 끝판왕 도쿄등심 도곡점​​​ ​​*  안녕하세요 제이드입니다. ...</td>\n",
       "      <td>[도곡동, 맛집, 분위기, 끝판, 도쿄, 등심, 도곡, 점, 제이드, 지난주, 저녁...</td>\n",
       "      <td>[도곡동, 맛집, 분위기, 끝판, 도쿄, 등심, 도곡, 제이드, 지난주, 저녁, 약...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>여의도는 수많은 빌딩들이 밀집되어 있어화려한 건축물의 조명등으로 야경이 아름다운  ...</td>\n",
       "      <td>[여의도, 빌딩, 밀집, 건축물, 조명등, 야경, 서울, 대표, 오피스, 상권, 더...</td>\n",
       "      <td>[여의도, 빌딩, 밀집, 건축물, 조명등, 야경, 서울, 대표, 오피스, 상권, 도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>도쿄등심 여의도점 - 분위기 좋은 여의도 데이트 맛집, 기념일 맛집으로 추천해!​안...</td>\n",
       "      <td>[도쿄, 등심, 여의도, 점, 분위기, 여의도, 데이트, 맛집, 기념일, 맛집, 추...</td>\n",
       "      <td>[도쿄, 등심, 여의도, 분위기, 여의도, 데이트, 맛집, 기념일, 맛집, 추천, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>​오늘은 히나랑 디~즈니란도 가는 날 ~JR 시계 여기는 스페이드모양이다 귀여워마이...</td>\n",
       "      <td>[오늘, 나, 디, 란, 날, 시계, 스페, 이드, 모양, 하마, 역, 도키, 도키...</td>\n",
       "      <td>[오늘, 시계, 스페, 이드, 모양, 하마, 도키, 도키, 와쿠, 와쿠, 별거, 유...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>도쿄에서는 단풍이 절정을 맞이하고 있어요!오늘은 추천 단풍명소를 소개해 드릴게요. ...</td>\n",
       "      <td>[도쿄, 단풍, 절정, 맞이, 오늘, 추천, 단풍, 명소, 소개, 코로나, 사태, ...</td>\n",
       "      <td>[도쿄, 단풍, 절정, 맞이, 오늘, 추천, 단풍, 명소, 소개, 코로나, 사태, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021년 11월의 기록...PART 1이제 슬슬 노랑 노랑해지기 시작한.....도...</td>\n",
       "      <td>[기록, 이제, 슬슬, 노랑, 노랑, 시작, 도쿄, 단풍, 명소, 진구, 은행나무,...</td>\n",
       "      <td>[기록, 이제, 슬슬, 노랑, 노랑, 시작, 도쿄, 단풍, 명소, 진구, 은행나무,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>안녕하세요, 도쿄드라이브입니다. 긴자(銀座)는 쇼핑하기 참좋은 도쿄의 유명 관광스팟...</td>\n",
       "      <td>[도쿄, 드라이브, 긴자, 쇼핑, 도쿄, 유명, 관광, 스팟, 요, 명품, 레스토랑...</td>\n",
       "      <td>[도쿄, 드라이브, 긴자, 쇼핑, 도쿄, 유명, 관광, 스팟, 명품, 레스토랑, 거...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>도쿄 리벤저스 만화 원화전 , 오사카서 내년 열려 티저 비주얼 공개와쿠이 켄 도쿄...</td>\n",
       "      <td>[리벤저스, 만화, 화전, 오사카, 내년, 티저, 비주, 얼, 공개, 와쿠, 켄, ...</td>\n",
       "      <td>[리벤저스, 만화, 화전, 오사카, 내년, 티저, 비주, 공개, 와쿠, 도쿄, 리벤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021.11.16 (화) 329일차​​​​6:30-11 도토루하 데마에칸 진짜,,...</td>\n",
       "      <td>[화, 도토, 루하, 데마, 칸, 진짜, 난, 그, 배달, 그, 관, 요캇타, 오늘...</td>\n",
       "      <td>[도토, 루하, 데마, 진짜, 배달, 요캇타, 오늘, 뭔가, 정말, 맥날, 가기, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>​ 일본유학 중국유학북경어언대학교 도쿄분교​ ​​중국의 북경어언대학교는1962년 중...</td>\n",
       "      <td>[일본, 유학, 중국, 유학, 북경어언대, 학교, 도쿄, 분교, 중국, 북경어언대,...</td>\n",
       "      <td>[일본, 유학, 중국, 유학, 북경어언대, 학교, 도쿄, 분교, 중국, 북경어언대,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>오늘은 충동질로 버스표 끊은 카와구치코 가는 날^^일기예보도 안보고 아 갈까? 가야...</td>\n",
       "      <td>[오늘, 충, 질, 버스, 표, 카와구치, 코, 날, 일기예보, 안보, 가야, 징,...</td>\n",
       "      <td>[오늘, 버스, 카와구치, 일기예보, 안보, 가야, 사스, 레온, 오늘, 날씨, 최...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>디너코스 B 으로 먹었어요남편과 저 둘이서 간만에 데이트 하는느낌으로 먹었는데 분위...</td>\n",
       "      <td>[디, 코스, 남편, 저, 둘이서, 간만, 데이트, 느낌, 분위기, 정글, 느낌, ...</td>\n",
       "      <td>[코스, 남편, 둘이서, 간만, 데이트, 느낌, 분위기, 정글, 느낌, 매봉역, 맛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>광교에 간 김에 점심을 먹으러 앨리웨이(Alleyway)에 갔다. &lt; 광교 앨리웨이...</td>\n",
       "      <td>[광교, 간, 김, 점심, 앨리, 웨이, 광교, 앨리, 웨이, 요즈음, 광교, 우리...</td>\n",
       "      <td>[광교, 점심, 앨리, 웨이, 광교, 앨리, 웨이, 요즈음, 광교, 우리, 인생, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>smartparty.jp곤니치와 ~^^\"일본여행 크리에이터 난짱이야.​​먼저 매번 ...</td>\n",
       "      <td>[곤, 치, 일본여행, 크리에이터, 난, 먼저, 매번, 말, 이, 글, 편의, 반말...</td>\n",
       "      <td>[일본여행, 크리에이터, 먼저, 매번, 편의, 반말, 대해, 미리, 양해, 공간, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>오늘은 👶 기다리는 요미우리랜드 ( 🎡 유원지 ) 遊園地よみうりランド遊園地よみうりラ...</td>\n",
       "      <td>[오늘, 요미우리랜드, 유원지, 늦잠, 충전, 잠, 정도, 해결, 오늘, 산들, 산...</td>\n",
       "      <td>[오늘, 요미우리랜드, 유원지, 늦잠, 충전, 해결, 오늘, 산들, 산들, 가을, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>아 얘들아 내가 아직 얘길 안했지 아이폰13 샀다고...(출시때 직구함)(미니 스타...</td>\n",
       "      <td>[얘, 내, 얘길, 아이폰, 출시, 때, 직구, 함, 미니, 스타, 라이트, 컬러,...</td>\n",
       "      <td>[얘길, 아이폰, 출시, 직구, 미니, 스타, 라이트, 컬러, 사진, 업로드, 쌔폰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>남친보다 친구만나는날에 더 머리랑 화장을 공들여한다...왜냐..사진 오조억장 찍거든...</td>\n",
       "      <td>[남친, 친구, 날, 더, 머리, 화장, 공, 왜, 사진, 오조억, 신고, 포쨕, ...</td>\n",
       "      <td>[남친, 친구, 머리, 화장, 사진, 오조억, 신고, 포쨕, 미리, 예약, 점심, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>안녕하세요, 도쿄드라이브입니다. 이번 포스팅은 도쿄의 트렌디한 고급동네 오모테산도(...</td>\n",
       "      <td>[도쿄, 드라이브, 이번, 포스팅, 도쿄, 트렌디, 고급, 동네, 오모테산도, 위치...</td>\n",
       "      <td>[도쿄, 드라이브, 포스팅, 도쿄, 트렌디, 고급, 동네, 오모테산도, 위치, 고기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>아트를 좋아하시는 분이 놓치면 후회할 호텔을 소개해 드릴게요! ​   도쿄·신바시에...</td>\n",
       "      <td>[아트, 분, 후회, 호텔, 소개, 도쿄, 신바시, 객실, 예술, 작품, 파크, 호...</td>\n",
       "      <td>[아트, 후회, 호텔, 소개, 도쿄, 신바시, 객실, 예술, 작품, 파크, 호텔, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>안녕하세요, 도쿄드라이브입니다. 일본 도쿄에서 쇼핑하기 좋은 동네는 몇군데 있는데요...</td>\n",
       "      <td>[도쿄, 드라이브, 일본, 도쿄, 쇼핑, 동네, 군데, 긴자, 조금, 연령, 대가,...</td>\n",
       "      <td>[도쿄, 드라이브, 일본, 도쿄, 쇼핑, 동네, 군데, 긴자, 조금, 연령, 대가,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>오늘은 탈리즈 7-10시프트!끝나고 뭐할까 고민하다가이제 있을 시간도 얼마 안남았으...</td>\n",
       "      <td>[오늘, 탈, 리즈, 뭐, 고민, 이제, 시간, 얼마, 산책, 루, 패, 홍차, 휘...</td>\n",
       "      <td>[오늘, 리즈, 고민, 이제, 시간, 얼마, 산책, 홍차, 낭시, 마쉬땅, 아침, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>안녕하세요, 도쿄드라이브입니다. 최근 도쿄는 긴급사태선언(緊急事態宣言)이 끝나고, ...</td>\n",
       "      <td>[도쿄, 드라이브, 최근, 도쿄, 긴급, 사태, 선언, 이, 위드, 코로나, 시대,...</td>\n",
       "      <td>[도쿄, 드라이브, 최근, 도쿄, 긴급, 사태, 선언, 위드, 코로나, 시대, 진입...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body  \\\n",
       "0   청담 파인다이닝 도쿄등심에서 이렇게 한우를 드세요도쿄등심 청담점에 다녀왔습니다.누네...   \n",
       "1   날씨도 추워졌겠다 오랜만에 너덜너덜해진 열손가락의 꽃단장을 위하여 덕천동 네일로 향...   \n",
       "2   안녕하세요, 도쿄드라이브입니다. 최근 롤렉스나 에르메스의 인기모델들은 정식매장에 가...   \n",
       "3   2021.11.17 아침 사진이 하나뚜 없ㄴㅔ건강보험 뭐 우편 온거 땜에 일어나서 ...   \n",
       "4   곧 다가올 와이프님과의 5주년 결혼기념일.​포근한 주말을 맞이하여 분당에서 광교앨리...   \n",
       "5   와 나 300일이나 여기에 살았네..3일째랑 30일째 되는 날엔 뭘 했지...?기억...   \n",
       "6   선릉역 소고기 맛집 도쿄등심선릉점 와이프와 함께 코엑스 전시보고 맛있는 소고기 먹으...   \n",
       "7   작은도쿄평일 11:30~21:00브레이크타임 15:00~17:00토일,공휴일 휴무숙...   \n",
       "8   도곡동 맛집 분위기 끝판왕 도쿄등심 도곡점​​​ ​​*  안녕하세요 제이드입니다. ...   \n",
       "9   여의도는 수많은 빌딩들이 밀집되어 있어화려한 건축물의 조명등으로 야경이 아름다운  ...   \n",
       "10  도쿄등심 여의도점 - 분위기 좋은 여의도 데이트 맛집, 기념일 맛집으로 추천해!​안...   \n",
       "11  ​오늘은 히나랑 디~즈니란도 가는 날 ~JR 시계 여기는 스페이드모양이다 귀여워마이...   \n",
       "12  도쿄에서는 단풍이 절정을 맞이하고 있어요!오늘은 추천 단풍명소를 소개해 드릴게요. ...   \n",
       "13  2021년 11월의 기록...PART 1이제 슬슬 노랑 노랑해지기 시작한.....도...   \n",
       "14  안녕하세요, 도쿄드라이브입니다. 긴자(銀座)는 쇼핑하기 참좋은 도쿄의 유명 관광스팟...   \n",
       "15   도쿄 리벤저스 만화 원화전 , 오사카서 내년 열려 티저 비주얼 공개와쿠이 켄 도쿄...   \n",
       "16  2021.11.16 (화) 329일차​​​​6:30-11 도토루하 데마에칸 진짜,,...   \n",
       "17  ​ 일본유학 중국유학북경어언대학교 도쿄분교​ ​​중국의 북경어언대학교는1962년 중...   \n",
       "18  오늘은 충동질로 버스표 끊은 카와구치코 가는 날^^일기예보도 안보고 아 갈까? 가야...   \n",
       "19  디너코스 B 으로 먹었어요남편과 저 둘이서 간만에 데이트 하는느낌으로 먹었는데 분위...   \n",
       "20  광교에 간 김에 점심을 먹으러 앨리웨이(Alleyway)에 갔다. < 광교 앨리웨이...   \n",
       "21  smartparty.jp곤니치와 ~^^\"일본여행 크리에이터 난짱이야.​​먼저 매번 ...   \n",
       "22  오늘은 👶 기다리는 요미우리랜드 ( 🎡 유원지 ) 遊園地よみうりランド遊園地よみうりラ...   \n",
       "23  아 얘들아 내가 아직 얘길 안했지 아이폰13 샀다고...(출시때 직구함)(미니 스타...   \n",
       "24  남친보다 친구만나는날에 더 머리랑 화장을 공들여한다...왜냐..사진 오조억장 찍거든...   \n",
       "25  안녕하세요, 도쿄드라이브입니다. 이번 포스팅은 도쿄의 트렌디한 고급동네 오모테산도(...   \n",
       "26  아트를 좋아하시는 분이 놓치면 후회할 호텔을 소개해 드릴게요! ​   도쿄·신바시에...   \n",
       "27  안녕하세요, 도쿄드라이브입니다. 일본 도쿄에서 쇼핑하기 좋은 동네는 몇군데 있는데요...   \n",
       "28  오늘은 탈리즈 7-10시프트!끝나고 뭐할까 고민하다가이제 있을 시간도 얼마 안남았으...   \n",
       "29  안녕하세요, 도쿄드라이브입니다. 최근 도쿄는 긴급사태선언(緊急事態宣言)이 끝나고, ...   \n",
       "\n",
       "                                    comment_okt_nouns  \\\n",
       "0   [청담, 다이닝, 도쿄, 등심, 한우, 도쿄, 등심, 청담, 점, 누, 안과, 신랑...   \n",
       "1   [날씨, 만, 손가락, 꽃, 단장, 위, 덕천동, 네일, 향, 제, 성격, 좀, 무...   \n",
       "2   [도쿄, 드라이브, 최근, 롤렉스, 에르메스, 인기, 모델, 정식, 매장, 가면, ...   \n",
       "3   [아침, 사진, 하나, 뚜, 건강, 보험, 뭐, 우편, 땜, 일어나서, 고구마, 고...   \n",
       "4   [곧, 와이프, 주년, 결혼기념일, 주말, 맞이, 분당, 광교, 앨리, 웨이, 데이...   \n",
       "5   [나, 여기, 날, 뭘, 기억, 힝, 이제, 집, 전철, 때, 쭉, 신주쿠, 히가시...   \n",
       "6   [선릉역, 소고기, 맛집, 도쿄, 등심, 선릉, 점, 와이프, 코엑스, 전시, 보고...   \n",
       "7   [도쿄, 평일, 브레이크, 타임, 토일, 공휴일, 휴무, 숙대입구역, 근처, 늘, ...   \n",
       "8   [도곡동, 맛집, 분위기, 끝판, 도쿄, 등심, 도곡, 점, 제이드, 지난주, 저녁...   \n",
       "9   [여의도, 빌딩, 밀집, 건축물, 조명등, 야경, 서울, 대표, 오피스, 상권, 더...   \n",
       "10  [도쿄, 등심, 여의도, 점, 분위기, 여의도, 데이트, 맛집, 기념일, 맛집, 추...   \n",
       "11  [오늘, 나, 디, 란, 날, 시계, 스페, 이드, 모양, 하마, 역, 도키, 도키...   \n",
       "12  [도쿄, 단풍, 절정, 맞이, 오늘, 추천, 단풍, 명소, 소개, 코로나, 사태, ...   \n",
       "13  [기록, 이제, 슬슬, 노랑, 노랑, 시작, 도쿄, 단풍, 명소, 진구, 은행나무,...   \n",
       "14  [도쿄, 드라이브, 긴자, 쇼핑, 도쿄, 유명, 관광, 스팟, 요, 명품, 레스토랑...   \n",
       "15  [리벤저스, 만화, 화전, 오사카, 내년, 티저, 비주, 얼, 공개, 와쿠, 켄, ...   \n",
       "16  [화, 도토, 루하, 데마, 칸, 진짜, 난, 그, 배달, 그, 관, 요캇타, 오늘...   \n",
       "17  [일본, 유학, 중국, 유학, 북경어언대, 학교, 도쿄, 분교, 중국, 북경어언대,...   \n",
       "18  [오늘, 충, 질, 버스, 표, 카와구치, 코, 날, 일기예보, 안보, 가야, 징,...   \n",
       "19  [디, 코스, 남편, 저, 둘이서, 간만, 데이트, 느낌, 분위기, 정글, 느낌, ...   \n",
       "20  [광교, 간, 김, 점심, 앨리, 웨이, 광교, 앨리, 웨이, 요즈음, 광교, 우리...   \n",
       "21  [곤, 치, 일본여행, 크리에이터, 난, 먼저, 매번, 말, 이, 글, 편의, 반말...   \n",
       "22  [오늘, 요미우리랜드, 유원지, 늦잠, 충전, 잠, 정도, 해결, 오늘, 산들, 산...   \n",
       "23  [얘, 내, 얘길, 아이폰, 출시, 때, 직구, 함, 미니, 스타, 라이트, 컬러,...   \n",
       "24  [남친, 친구, 날, 더, 머리, 화장, 공, 왜, 사진, 오조억, 신고, 포쨕, ...   \n",
       "25  [도쿄, 드라이브, 이번, 포스팅, 도쿄, 트렌디, 고급, 동네, 오모테산도, 위치...   \n",
       "26  [아트, 분, 후회, 호텔, 소개, 도쿄, 신바시, 객실, 예술, 작품, 파크, 호...   \n",
       "27  [도쿄, 드라이브, 일본, 도쿄, 쇼핑, 동네, 군데, 긴자, 조금, 연령, 대가,...   \n",
       "28  [오늘, 탈, 리즈, 뭐, 고민, 이제, 시간, 얼마, 산책, 루, 패, 홍차, 휘...   \n",
       "29  [도쿄, 드라이브, 최근, 도쿄, 긴급, 사태, 선언, 이, 위드, 코로나, 시대,...   \n",
       "\n",
       "                            comment_okt_nouns_len_stp  \n",
       "0   [청담, 다이닝, 도쿄, 등심, 한우, 도쿄, 등심, 청담, 안과, 신랑, 라섹, ...  \n",
       "1   [날씨, 손가락, 단장, 덕천동, 네일, 성격, 무딘편, 변화, 대해, 크게, 신경...  \n",
       "2   [도쿄, 드라이브, 최근, 롤렉스, 에르메스, 인기, 모델, 정식, 매장, 가면, ...  \n",
       "3   [아침, 사진, 건강, 보험, 우편, 일어나서, 고구마, 고민, 기어, 사실, 약간...  \n",
       "4   [와이프, 주년, 결혼기념일, 주말, 맞이, 분당, 광교, 앨리, 웨이, 데이트, ...  \n",
       "5   [기억, 이제, 전철, 신주쿠, 히가시구, 치쪽, 해도, 진단, 오늘, 오픈, 멤버...  \n",
       "6   [선릉역, 소고기, 맛집, 도쿄, 등심, 선릉, 와이프, 코엑스, 전시, 보고, 소...  \n",
       "7   [도쿄, 평일, 브레이크, 타임, 토일, 공휴일, 휴무, 숙대입구역, 근처, 웨이팅...  \n",
       "8   [도곡동, 맛집, 분위기, 끝판, 도쿄, 등심, 도곡, 제이드, 지난주, 저녁, 약...  \n",
       "9   [여의도, 빌딩, 밀집, 건축물, 조명등, 야경, 서울, 대표, 오피스, 상권, 도...  \n",
       "10  [도쿄, 등심, 여의도, 분위기, 여의도, 데이트, 맛집, 기념일, 맛집, 추천, ...  \n",
       "11  [오늘, 시계, 스페, 이드, 모양, 하마, 도키, 도키, 와쿠, 와쿠, 별거, 유...  \n",
       "12  [도쿄, 단풍, 절정, 맞이, 오늘, 추천, 단풍, 명소, 소개, 코로나, 사태, ...  \n",
       "13  [기록, 이제, 슬슬, 노랑, 노랑, 시작, 도쿄, 단풍, 명소, 진구, 은행나무,...  \n",
       "14  [도쿄, 드라이브, 긴자, 쇼핑, 도쿄, 유명, 관광, 스팟, 명품, 레스토랑, 거...  \n",
       "15  [리벤저스, 만화, 화전, 오사카, 내년, 티저, 비주, 공개, 와쿠, 도쿄, 리벤...  \n",
       "16  [도토, 루하, 데마, 진짜, 배달, 요캇타, 오늘, 뭔가, 정말, 맥날, 가기, ...  \n",
       "17  [일본, 유학, 중국, 유학, 북경어언대, 학교, 도쿄, 분교, 중국, 북경어언대,...  \n",
       "18  [오늘, 버스, 카와구치, 일기예보, 안보, 가야, 사스, 레온, 오늘, 날씨, 최...  \n",
       "19  [코스, 남편, 둘이서, 간만, 데이트, 느낌, 분위기, 정글, 느낌, 매봉역, 맛...  \n",
       "20  [광교, 점심, 앨리, 웨이, 광교, 앨리, 웨이, 요즈음, 광교, 우리, 인생, ...  \n",
       "21  [일본여행, 크리에이터, 먼저, 매번, 편의, 반말, 대해, 미리, 양해, 공간, ...  \n",
       "22  [오늘, 요미우리랜드, 유원지, 늦잠, 충전, 해결, 오늘, 산들, 산들, 가을, ...  \n",
       "23  [얘길, 아이폰, 출시, 직구, 미니, 스타, 라이트, 컬러, 사진, 업로드, 쌔폰...  \n",
       "24  [남친, 친구, 머리, 화장, 사진, 오조억, 신고, 포쨕, 미리, 예약, 점심, ...  \n",
       "25  [도쿄, 드라이브, 포스팅, 도쿄, 트렌디, 고급, 동네, 오모테산도, 위치, 고기...  \n",
       "26  [아트, 후회, 호텔, 소개, 도쿄, 신바시, 객실, 예술, 작품, 파크, 호텔, ...  \n",
       "27  [도쿄, 드라이브, 일본, 도쿄, 쇼핑, 동네, 군데, 긴자, 조금, 연령, 대가,...  \n",
       "28  [오늘, 리즈, 고민, 이제, 시간, 얼마, 산책, 홍차, 낭시, 마쉬땅, 아침, ...  \n",
       "29  [도쿄, 드라이브, 최근, 도쿄, 긴급, 사태, 선언, 위드, 코로나, 시대, 진입...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "h1czWti1cHv1"
   },
   "outputs": [],
   "source": [
    "# 특수문자 제거\n",
    "#df.comment_okt_nouns_len_stp = df.comment_okt_nouns_len_stp.str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PmeDyXCwcHv2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 숫자 제거\n",
    "#df.comment_okt_nouns_len_stp = df.comment_okt_nouns_len_stp.str.replace(r'\\d+','')\n",
    "#comment_okt_nouns_len_stp = df.comment_okt_nouns_len_stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bigram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-33a280508b4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Faster way to get a sentence clubbed as a trigram/bigram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbigram_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphrases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhraser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbigram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtrigram_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphrases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhraser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrigram\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bigram' is not defined"
     ]
    }
   ],
   "source": [
    "#bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "#trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LczitnlDcHv3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bigram_mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-94c6c8c18d68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrigram_mod\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbigram_mod\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdata_words_bigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_bigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment_okt_nouns_len_stp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mid2word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_words_bigrams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_words_bigrams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-94c6c8c18d68>\u001b[0m in \u001b[0;36mmake_bigrams\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# bigram 모델 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_bigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbigram_mod\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_trigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-94c6c8c18d68>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# bigram 모델 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_bigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbigram_mod\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_trigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bigram_mod' is not defined"
     ]
    }
   ],
   "source": [
    "# bigram 모델 생성\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "data_words_bigrams = make_bigrams(comment_okt_nouns_len_stp)\n",
    "id2word = corpora.Dictionary(data_words_bigrams)\n",
    "texts = data_words_bigrams\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "nSdYoSX_cHv5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.models.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d2c14e5b0a25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#LDA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLdaMallet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mldamallet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLdaMallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim.models.wrappers'"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "ldamallet = LdaMallet(mallet_path, corpus=corpus, num_topics=30, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wI7zi9btcHv7"
   },
   "outputs": [],
   "source": [
    "# coherence 평가\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "  \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "#k = 5,10,15,20 한 결과 k = 10 선택\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_words_bigrams, start=5, limit=25, step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucpNrgCFcHv9"
   },
   "outputs": [],
   "source": [
    "# document 별 topic 확률 확인하는 dataframe 만들기\n",
    "idx,topic0,topic1,topic2,topic3,topic4,topic5,topic6,topic7,topic8,topic9=[],[],[],[],[],[],[],[],[],[],[]\n",
    "for i in range(len(corpus)):\n",
    "  document_topics = gensimmodel10.get_document_topics(corpus[i])\n",
    "  idx.append(i)\n",
    "  topic0.append(document_topics[0][1])\n",
    "  topic1.append(document_topics[1][1])\n",
    "  topic2.append(document_topics[2][1])\n",
    "  topic3.append(document_topics[3][1])\n",
    "  topic4.append(document_topics[4][1])\n",
    "  topic5.append(document_topics[5][1])\n",
    "  topic6.append(document_topics[6][1])\n",
    "  topic7.append(document_topics[7][1])\n",
    "  topic8.append(document_topics[8][1])\n",
    "  topic9.append(document_topics[9][1])\n",
    "df_topic_probs_df['idx'] = idx\n",
    "df_topic_probs_df['topic0'] = topic0\n",
    "df_topic_probs_df['topic1'] = topic1\n",
    "df_topic_probs_df['topic2'] = topic2\n",
    "df_topic_probs_df['topic3'] = topic3\n",
    "df_topic_probs_df['topic4'] = topic4\n",
    "df_topic_probs_df['topic5'] = topic5\n",
    "df_topic_probs_df['topic6'] = topic6\n",
    "df_topic_probs_df['topic7'] = topic7\n",
    "df_topic_probs_df['topic8'] = topic8\n",
    "df_topic_probs_df['topic9'] = topic9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfWoZIcxcHv_"
   },
   "outputs": [],
   "source": [
    "# document별로 topic 확률을 토대로 속성 확률 구하기\n",
    "df_topic_probs_df['att1'] = (df_topic_probs_df['topic0']+ df_topic_probs_df['topic1']+ df_topic_probs_df['topic3']+ df_topic_probs_df['topic6'] + df_topic_probs_df['topic9'])/5\n",
    "df_topic_probs_df['att2'] = (df_topic_probs_df['topic2']+df_topic_probs_df['topic5']+df_topic_probs_df['topic7'])/3\n",
    "df_topic_probs_df['att3'] = (df_topic_probs_df['topic4']+df_topic_probs_df['topic8'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUPtSuelcHwA"
   },
   "outputs": [],
   "source": [
    "df_topic_probs_df = df_topic_probs_df[['att1','att2','att3']]\n",
    "df_topic_probs_df_argmax = []\n",
    "for i in range(len(df_topic_probs_df)):\n",
    "  df_topic_probs_df_argmax.append(np.argmax(df_topic_probs_df.loc[i]))\n",
    "df_topic_probs_df['argmax'] = df_topic_probs_df['argmax'] +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3w0DkZUcHwC"
   },
   "outputs": [],
   "source": [
    "df['attribute_num'] = df_topic_probs_df.argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1dGDqqWcHwE"
   },
   "source": [
    "# 영어 댓글 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8x_w4fScHwF"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/gdrive/Shareddrives/데청캠/웹툰 세계화/데이터 모음집/ew_2_comment.csv')\n",
    "df = df[['title_a','ep_title_a','num_list','best_comment']]\n",
    "for i in range(len(df)):\n",
    "  if df['best_comment'][i][:3]=='TOP':\n",
    "    df['best_comment'][i] = df['best_comment'][i][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-sdugW4cHwF"
   },
   "outputs": [],
   "source": [
    "# 명사 tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "result_nouns=[]\n",
    "for i in range(len(df)):\n",
    "  result_nouns.append([])\n",
    "\n",
    "for i in range(len(df)):\n",
    "  txt =  df.best_comment[i]\n",
    "  tokenized = nltk.word_tokenize(txt)\n",
    "  for word,pos in nltk.pos_tag(tokenized):\n",
    "    if pos[:2] == 'NN':\n",
    "      result_nouns[i].append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KejkpleScHwG"
   },
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "result_nouns_stopwords=[]\n",
    "for i in range(len(result_nouns)):\n",
    "  result_nouns_stopwords.append([])\n",
    "\n",
    "for i in range(len(result_nouns)):\n",
    "  for word in result_nouns[i]:\n",
    "    if word not in stop_words:\n",
    "      result_nouns_stopwords[i].append(word) #result_nouns_stopwords\n",
    "df['result_nouns_stopwords'] = result_nouns_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBPbUZkecHwH"
   },
   "outputs": [],
   "source": [
    "# 소문자로 바꾸기\n",
    "df.result_nouns_stopwords = df.result_nouns_stopwords.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGRWtOKwcHwI"
   },
   "outputs": [],
   "source": [
    "# 특수문자 제거\n",
    "df.result_nouns_stopwords = df.result_nouns_stopwords.str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fx7qw0YTcHwJ"
   },
   "outputs": [],
   "source": [
    "# 숫자 제거\n",
    "df.result_nouns_stopwords = df.result_nouns_stopwords.str.replace(r'\\d+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbMi1jZAcHwK"
   },
   "outputs": [],
   "source": [
    "# 길이가 짧은 단어 제거\n",
    "df.result_nouns_stopwords = df.result_nouns_stopwords.str.replace(r'\\W*\\b\\w{1,2}\\b','')\n",
    "result_nouns_stopwords = df.result_nouns_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I53QijHvcHwM"
   },
   "outputs": [],
   "source": [
    "# bigram 모델 생성\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "data_words_bigrams = make_bigrams(result_nouns_stopwords)\n",
    "id2word = corpora.Dictionary(data_words_bigrams)\n",
    "texts = data_words_bigrams\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJ6ZuShxcHwN"
   },
   "outputs": [],
   "source": [
    "# LDA\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "ldamallet = LdaMallet(mallet_path, corpus=corpus, num_topics=30, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZDOCF_xcHwO"
   },
   "outputs": [],
   "source": [
    "# coherence 평가\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "  \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "#k = 10,20,30,40 평가 하였고 k = 30 선택\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_words_bigrams, start=10, limit=50, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzSsUnONcHwP"
   },
   "outputs": [],
   "source": [
    "# document 별 topic 확률 확인하는 dataframe 만들기\n",
    "idx,topic0,topic1,topic2,topic3,topic4,topic5,topic6,topic7,topic8,topic9=[],[],[],[],[],[],[],[],[],[],[]\n",
    "topic10,topic11,topic12,topic13,topic14,topic15,topic16,topic17,topic18,topic19, = [],[],[],[],[],[],[],[],[],[]\n",
    "topic20,topic21,topic22,topic23,topic24,topic25,topic26,topic27,topic28,topic29 = [],[],[],[],[],[],[],[],[],[]\n",
    "for i in range(len(corpus)):\n",
    "  document_topics = gensimmodel30.get_document_topics(corpus[i])\n",
    "  idx.append(i)\n",
    "  try:\n",
    "    topic0.append(document_topics[0][1])\n",
    "  except:\n",
    "    topic0.append(0)\n",
    "  try:\n",
    "    topic1.append(document_topics[1][1])\n",
    "  except:\n",
    "    topic1.append(0)\n",
    "  try:\n",
    "    topic2.append(document_topics[2][1])\n",
    "  except:\n",
    "    topic2.append(0)\n",
    "  try:\n",
    "    topic3.append(document_topics[3][1])\n",
    "  except:\n",
    "    topic3.append(0)\n",
    "  try:\n",
    "    topic4.append(document_topics[4][1])\n",
    "  except:\n",
    "    topic4.append(0)  \n",
    "  try:\n",
    "    topic5.append(document_topics[5][1])\n",
    "  except:\n",
    "    topic5.append(0)  \n",
    "  try:\n",
    "    topic6.append(document_topics[6][1])\n",
    "  except:\n",
    "    topic6.append(0)\n",
    "  try:\n",
    "    topic7.append(document_topics[7][1])\n",
    "  except:\n",
    "    topic7.append(0)\n",
    "  try:\n",
    "    topic8.append(document_topics[8][1])\n",
    "  except:\n",
    "    topic8.append(0)\n",
    "  try:\n",
    "    topic9.append(document_topics[9][1])\n",
    "  except:\n",
    "    topic9.append(0)\n",
    "  try:\n",
    "    topic10.append(document_topics[10][1])\n",
    "  except:\n",
    "    topic10.append(0)\n",
    "  try:\n",
    "    topic11.append(document_topics[11][1])\n",
    "  except:\n",
    "    topic11.append(0)\n",
    "  try:\n",
    "    topic12.append(document_topics[12][1])\n",
    "  except:\n",
    "    topic12.append(0)\n",
    "  try:\n",
    "    topic13.append(document_topics[13][1])\n",
    "  except:\n",
    "    topic13.append(0)\n",
    "  try:\n",
    "    topic14.append(document_topics[14][1])\n",
    "  except:\n",
    "    topic14.append(0)\n",
    "  try:\n",
    "    topic15.append(document_topics[15][1])\n",
    "  except:\n",
    "    topic15.append(0)\n",
    "  try:\n",
    "    topic16.append(document_topics[16][1])\n",
    "  except:\n",
    "    topic16.append(0)\n",
    "  try:\n",
    "    topic17.append(document_topics[17][1])\n",
    "  except:\n",
    "    topic17.append(0)\n",
    "  try:\n",
    "    topic18.append(document_topics[18][1])\n",
    "  except:\n",
    "    topic18.append(0)\n",
    "  try:\n",
    "    topic19.append(document_topics[19][1])\n",
    "  except:\n",
    "    topic19.append(0)\n",
    "  try:\n",
    "    topic20.append(document_topics[20][1])\n",
    "  except:\n",
    "    topic20.append(0)\n",
    "  try:\n",
    "    topic21.append(document_topics[21][1])\n",
    "  except:\n",
    "    topic21.append(0)\n",
    "  try:\n",
    "    topic22.append(document_topics[22][1])\n",
    "  except:\n",
    "    topic22.append(0)\n",
    "  try:\n",
    "    topic23.append(document_topics[23][1])\n",
    "  except:\n",
    "    topic23.append(0)\n",
    "  try:\n",
    "    topic24.append(document_topics[24][1])\n",
    "  except:\n",
    "    topic24.append(0)\n",
    "  try:\n",
    "    topic25.append(document_topics[25][1])\n",
    "  except:\n",
    "    topic25.append(0)\n",
    "\n",
    "  try:\n",
    "    topic26.append(document_topics[26][1])\n",
    "  except:\n",
    "    topic26.append(0)\n",
    "\n",
    "  try:\n",
    "    topic27.append(document_topics[27][1])\n",
    "  except:\n",
    "    topic27.append(0)\n",
    "\n",
    "  try:\n",
    "    topic28.append(document_topics[28][1])\n",
    "  except:\n",
    "    topic28.append(0)\n",
    "  try:\n",
    "    topic29.append(document_topics[29][1])\n",
    "  except:\n",
    "    topic29.append(0)\n",
    "df_topic_probs_df['idx'] = idx\n",
    "df_topic_probs_df['topic0'] = topic0\n",
    "df_topic_probs_df['topic1'] = topic1\n",
    "df_topic_probs_df['topic2'] = topic2\n",
    "df_topic_probs_df['topic3'] = topic3\n",
    "df_topic_probs_df['topic4'] = topic4\n",
    "df_topic_probs_df['topic5'] = topic5\n",
    "df_topic_probs_df['topic6'] = topic6\n",
    "df_topic_probs_df['topic7'] = topic7\n",
    "df_topic_probs_df['topic8'] = topic8\n",
    "df_topic_probs_df['topic9'] = topic9\n",
    "df_topic_probs_df['topic10'] = topic10\n",
    "df_topic_probs_df['topic11'] = topic11\n",
    "df_topic_probs_df['topic12'] = topic12\n",
    "df_topic_probs_df['topic13'] = topic13\n",
    "df_topic_probs_df['topic14'] = topic14\n",
    "df_topic_probs_df['topic15'] = topic15\n",
    "df_topic_probs_df['topic16'] = topic16\n",
    "df_topic_probs_df['topic17'] = topic17\n",
    "df_topic_probs_df['topic18'] = topic18\n",
    "df_topic_probs_df['topic19'] = topic19\n",
    "df_topic_probs_df['topic20'] = topic20\n",
    "df_topic_probs_df['topic21'] = topic21\n",
    "df_topic_probs_df['topic22'] = topic22\n",
    "df_topic_probs_df['topic23'] = topic23\n",
    "df_topic_probs_df['topic24'] = topic24\n",
    "df_topic_probs_df['topic25'] = topic25\n",
    "df_topic_probs_df['topic26'] = topic26\n",
    "df_topic_probs_df['topic27'] = topic27\n",
    "df_topic_probs_df['topic28'] = topic28\n",
    "df_topic_probs_df['topic29'] = topic29\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLClnpsVcHwQ"
   },
   "outputs": [],
   "source": [
    "#document 별 topic 확률을 토대로 속성 확률 구하기\n",
    "df_topic_probs_df['att1'] = (df_topic_probs_df['topic1'] + df_topic_probs_df['topic2'] + df_topic_probs_df['topic3'] + df_topic_probs_df['topic4'] + df_topic_probs_df['topic5'] + df_topic_probs_df['topic6'] + df_topic_probs_df['topic7'] + df_topic_probs_df['topic8'] + df_topic_probs_df['topic9'] + df_topic_probs_df['topic11'] + df_topic_probs_df['topic12'] + df_topic_probs_df['topic13'] + df_topic_probs_df['topic14'] + + df_topic_probs_df['topic15']+ df_topic_probs_df['topic17']+ df_topic_probs_df['topic18']+ df_topic_probs_df['topic19']+ df_topic_probs_df['topic20']+ df_topic_probs_df['topic21']+ df_topic_probs_df['topic22']+ df_topic_probs_df['topic24']+ df_topic_probs_df['topic25']+ df_topic_probs_df['topic26']+ df_topic_probs_df['topic29']+df_topic_probs_df['topic28'])/25\n",
    "df_topic_probs_df['att2'] = (df_topic_probs_df['topic10']+df_topic_probs_df['topic16']+df_topic_probs_df['topic23'])/3\n",
    "df_topic_probs_df['att3'] = (df_topic_probs_df['topic0']+df_topic_probs_df['topic27'])/2\n",
    "\n",
    "df_topic_probs_df = df_topic_probs_df[['att1','att2','att3']]\n",
    "df_topic_probs_df_argmax = []\n",
    "for i in range(len(df_topic_probs_df)):\n",
    "  df_topic_probs_df_argmax.append(np.argmax(df_topic_probs_df.loc[i]))\n",
    "df_topic_probs_df['argmax'] = df_topic_probs_df['argmax'] +1\n",
    "df['attribute_num2'] = df_topic_probs_df.argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4ZdIw5QcSPN"
   },
   "source": [
    "# 한글 댓글 SNA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppNCiiu2cHwR"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqbFNXYZcHwS"
   },
   "outputs": [],
   "source": [
    "num_top_nouns = 70\n",
    "comment_nouns_counter = Counter(comment_mecab_nouns_len_stp_fin)\n",
    "comment_top_nouns = dict(comment_nouns_counter.most_common(num_top_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7FXvgrwcHwS"
   },
   "outputs": [],
   "source": [
    "comment_word2id = {w: i for i, w in enumerate(comment_top_nouns.keys())}\n",
    "comment_id2word = {i: w for i, w in enumerate(comment_top_nouns.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBEYlT6vcHwT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "comment_adjacent_matrix = np.zeros((num_top_nouns, num_top_nouns), int)\n",
    "for sentence in comment_mecab_nouns_len_stp_fin:\n",
    "    for wi, i in comment_word2id.items():\n",
    "        if wi in sentence:\n",
    "            for wj, j in comment_word2id.items():\n",
    "                if i != j and wj in sentence:\n",
    "                    comment_adjacent_matrix[i][j] += 1\n",
    "comment_adjacent_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bQTBD5bcHwU"
   },
   "outputs": [],
   "source": [
    "comment_network = nx.from_numpy_matrix(comment_adjacent_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6Eg7U8YcHwV"
   },
   "outputs": [],
   "source": [
    "# 폰트 확인\n",
    "!sudo apt-get install -y fonts-nanum\n",
    "!sudo fc-cache -fv\n",
    "!rm ~/.cache/matplotlib -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiF3WTEZcHwV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "path='/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font_name = fm.FontProperties(fname=path,size=10).get_name()\n",
    "print(font_name)\n",
    "plt.rc('font',family=font_name)\n",
    "fm._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dA6s5gQ9cHwV"
   },
   "outputs": [],
   "source": [
    "option = {\n",
    "    'node_color' : 'lightblue',\n",
    "    'node_size' : 2000\n",
    "}\n",
    "plt.figure(figsize=(20,20))\n",
    "nx.draw_spring(comment_network, labels=comment_id2word, font_family='NanumBarunGothic', **option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pqmgtMvcHwW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khM8mA6ycHwW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CckXaDkYcHwW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7juL-oXcHwX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQ7n7Q6gcHwX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tw4GYH4McHwX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAqs0S1VcHwX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lkgnxLZcHwY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqBVhXyBcHwY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4-bm-sYcHwY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8heLMkPcHwY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxRvdd-ocHwZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQJKaCOLcHwZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-RFbuN1cHwZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUk9-ClbcHwZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVoHHcylcHwZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oK5HviabcHwa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iOJ5AKUcHwa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaGJBZ6WcHwa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PKaKdT4cHwa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CotWMpzWcHwa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_w-IReCxcHwb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMsCCVyNcHwb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aALQ_ALcHwb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLw-WxbqcHwb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxpTCU_UcHwb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "댓글 전처리와 LDA 모델링, SNA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
